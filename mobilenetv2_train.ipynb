{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "import pandas as pd\n",
    "\n",
    "input_shape = (224, 224, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet_model = MobileNetV2(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "mobilenet_model.trainable = True\n",
    "# mobilenet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layer Type</th>\n",
       "      <th>Layer Name</th>\n",
       "      <th>Layer Trainable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>&lt;tensorflow.python.keras.engine.input_layer.In...</td>\n",
       "      <td>input_1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional....</td>\n",
       "      <td>Conv1_pad</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional....</td>\n",
       "      <td>Conv1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>&lt;tensorflow.python.keras.layers.normalization....</td>\n",
       "      <td>bn_Conv1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>&lt;tensorflow.python.keras.layers.advanced_activ...</td>\n",
       "      <td>Conv1_relu</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional....</td>\n",
       "      <td>block_16_project</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>151</td>\n",
       "      <td>&lt;tensorflow.python.keras.layers.normalization....</td>\n",
       "      <td>block_16_project_BN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152</td>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional....</td>\n",
       "      <td>Conv_1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153</td>\n",
       "      <td>&lt;tensorflow.python.keras.layers.normalization....</td>\n",
       "      <td>Conv_1_bn</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154</td>\n",
       "      <td>&lt;tensorflow.python.keras.layers.advanced_activ...</td>\n",
       "      <td>out_relu</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Layer Type           Layer Name  \\\n",
       "0    <tensorflow.python.keras.engine.input_layer.In...              input_1   \n",
       "1    <tensorflow.python.keras.layers.convolutional....            Conv1_pad   \n",
       "2    <tensorflow.python.keras.layers.convolutional....                Conv1   \n",
       "3    <tensorflow.python.keras.layers.normalization....             bn_Conv1   \n",
       "4    <tensorflow.python.keras.layers.advanced_activ...           Conv1_relu   \n",
       "..                                                 ...                  ...   \n",
       "150  <tensorflow.python.keras.layers.convolutional....     block_16_project   \n",
       "151  <tensorflow.python.keras.layers.normalization....  block_16_project_BN   \n",
       "152  <tensorflow.python.keras.layers.convolutional....               Conv_1   \n",
       "153  <tensorflow.python.keras.layers.normalization....            Conv_1_bn   \n",
       "154  <tensorflow.python.keras.layers.advanced_activ...             out_relu   \n",
       "\n",
       "     Layer Trainable  \n",
       "0               True  \n",
       "1               True  \n",
       "2               True  \n",
       "3               True  \n",
       "4               True  \n",
       "..               ...  \n",
       "150             True  \n",
       "151             True  \n",
       "152             True  \n",
       "153             True  \n",
       "154             True  \n",
       "\n",
       "[155 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers = [(layer, layer.name, layer.trainable) for layer in mobilenet_model.layers]\n",
    "pd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import InputLayer\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3061 images belonging to 2 classes.\n",
      "Found 791 images belonging to 2 classes.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenetv2_1.00_224 (Model) (None, 7, 7, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 2562      \n",
      "=================================================================\n",
      "Total params: 2,260,546\n",
      "Trainable params: 2,226,434\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n",
      "Train for 765 steps, validate for 197 steps\n",
      "Epoch 1/20\n",
      "765/765 [==============================] - 131s 171ms/step - loss: 0.2707 - accuracy: 0.8813 - val_loss: 0.1441 - val_accuracy: 0.9467\n",
      "Epoch 2/20\n",
      "765/765 [==============================] - 118s 155ms/step - loss: 0.1263 - accuracy: 0.9529 - val_loss: 0.0693 - val_accuracy: 0.9835\n",
      "Epoch 3/20\n",
      "765/765 [==============================] - 118s 155ms/step - loss: 0.0484 - accuracy: 0.9843 - val_loss: 0.0205 - val_accuracy: 0.9962\n",
      "Epoch 4/20\n",
      "765/765 [==============================] - 119s 155ms/step - loss: 0.0427 - accuracy: 0.9850 - val_loss: 0.0387 - val_accuracy: 0.9898\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255, \n",
    "                                   zoom_range=0.3, \n",
    "                                   rotation_range=50,\n",
    "                                   width_shift_range=0.2, \n",
    "                                   height_shift_range=0.2, \n",
    "                                   shear_range=0.2, \n",
    "                                   horizontal_flip=True, \n",
    "                                   fill_mode='nearest')\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "dataset_path = 'dataset'\n",
    "train_set_path = os.path.join(dataset_path, 'train')\n",
    "val_set_path = os.path.join(dataset_path, 'test')\n",
    "BATCH_SIZE = 4\n",
    "TARGET_SIZE = input_shape[:2]\n",
    "train_generator = train_datagen.flow_from_directory(train_set_path,\n",
    "                                                 target_size = TARGET_SIZE,\n",
    "                                                 batch_size = BATCH_SIZE,\n",
    "                                                 class_mode = 'categorical')\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(val_set_path,\n",
    "                                                target_size = TARGET_SIZE,\n",
    "                                                batch_size = BATCH_SIZE,\n",
    "                                                class_mode = 'categorical')\n",
    "model = Sequential()\n",
    "model.add(mobilenet_model)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(units=2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                               min_delta=0,\n",
    "                               patience=1,\n",
    "                               verbose=0,\n",
    "                               mode='auto')\n",
    "\n",
    "EPOCHS = 20\n",
    "history = model.fit(train_generator, \n",
    "                    steps_per_epoch=train_generator.n // BATCH_SIZE, \n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=val_generator, \n",
    "                    validation_steps=val_generator.n // BATCH_SIZE, \n",
    "                    verbose=1,\n",
    "                    callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Fresh_Rotten_Fruits_MobileNetV2_Transfer_Learning.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "# t = f.suptitle('Pre-trained MobileNetV2 Transfer Learn with Fine-Tuning & Image Augmentation Performance ', fontsize=12)\n",
    "# f.subplots_adjust(top=0.85, wspace=0.3)\n",
    "\n",
    "# epoch_list = list(range(1,EPOCHS+1))\n",
    "# ax1.plot(epoch_list, history.history['accuracy'], label='Train Accuracy')\n",
    "# ax1.plot(epoch_list, history.history['val_accuracy'], label='Validation Accuracy')\n",
    "# ax1.set_xticks(np.arange(0, EPOCHS+1, 1))\n",
    "# ax1.set_ylabel('Accuracy Value')\n",
    "# ax1.set_xlabel('Epoch #')\n",
    "# ax1.set_title('Accuracy')\n",
    "# l1 = ax1.legend(loc=\"best\")\n",
    "\n",
    "# ax2.plot(epoch_list, history.history['loss'], label='Train Loss')\n",
    "# ax2.plot(epoch_list, history.history['val_loss'], label='Validation Loss')\n",
    "# ax2.set_xticks(np.arange(0, EPOCHS+1, 1))\n",
    "# ax2.set_ylabel('Loss Value')\n",
    "# ax2.set_xlabel('Epoch #')\n",
    "# ax2.set_title('Loss')\n",
    "# l2 = ax2.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
